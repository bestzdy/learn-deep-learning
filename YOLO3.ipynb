{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-29 21:42:18,559] [    INFO] 3339779238.py:946 - start train YOLOv3, train params:{'data_dir': 'data/data6045', 'train_list': 'train.txt', 'eval_list': 'eval.txt', 'class_dim': 2, 'label_dict': {'bolt': 0, 'nut': 1}, 'num_dict': {0: 'bolt', 1: 'nut'}, 'image_count': 410, 'continue_train': True, 'pretrained': False, 'pretrained_model_dir': './pretrained-model', 'save_model_dir': './yolo-model', 'model_prefix': 'yolo-v3', 'freeze_dir': 'freeze_model', 'use_tiny': True, 'max_box_num': 20, 'num_epochs': 40, 'train_batch_size': 32, 'use_gpu': True, 'yolo_cfg': {'input_size': [3, 448, 448], 'anchors': [7, 10, 12, 22, 24, 17, 22, 45, 46, 33, 43, 88, 85, 66, 115, 146, 275, 240], 'anchor_mask': [[6, 7, 8], [3, 4, 5], [0, 1, 2]]}, 'yolo_tiny_cfg': {'input_size': [3, 256, 256], 'anchors': [6, 8, 13, 15, 22, 34, 48, 50, 81, 100, 205, 191], 'anchor_mask': [[3, 4, 5], [0, 1, 2]]}, 'ignore_thresh': 0.7, 'mean_rgb': [127.5, 127.5, 127.5], 'mode': 'train', 'multi_data_reader_count': 4, 'apply_distort': True, 'nms_top_k': 300, 'nms_pos_k': 300, 'valid_thresh': 0.01, 'nms_thresh': 0.45, 'image_distort_strategy': {'expand_prob': 0.5, 'expand_max_ratio': 4, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'sgd_strategy': {'learning_rate': 0.002, 'lr_epochs': [30, 50, 65], 'lr_decay': [1, 0.5, 0.25, 0.1]}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 3, 'min_loss': 2.5, 'min_curr_map': 0.84}}\n",
      "[2023-10-29 21:42:18,560] [    INFO] 3339779238.py:947 - create place, use gpu:True\n",
      "[2023-10-29 21:42:18,561] [    INFO] 3339779238.py:951 - build network and program\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'paddle.fluid.layers' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1013\u001b[0m\n\u001b[0;32m   1009\u001b[0m     fluid\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39msave_persistables(dirname\u001b[38;5;241m=\u001b[39mtrain_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msave_model_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], main_program\u001b[38;5;241m=\u001b[39mtrain_program, executor\u001b[38;5;241m=\u001b[39mexe)\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1013\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 954\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    952\u001b[0m train_program \u001b[38;5;241m=\u001b[39m fluid\u001b[38;5;241m.\u001b[39mProgram()\n\u001b[0;32m    953\u001b[0m start_program \u001b[38;5;241m=\u001b[39m fluid\u001b[38;5;241m.\u001b[39mProgram()\n\u001b[1;32m--> 954\u001b[0m feeder, reader, loss \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_program_with_feeder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild executor and init params\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    958\u001b[0m exe \u001b[38;5;241m=\u001b[39m fluid\u001b[38;5;241m.\u001b[39mExecutor(place)\n",
      "Cell \u001b[1;32mIn[3], line 878\u001b[0m, in \u001b[0;36mbuild_program_with_feeder\u001b[1;34m(main_prog, startup_prog, place)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fluid\u001b[38;5;241m.\u001b[39mprogram_guard(main_prog, startup_prog):  \u001b[38;5;66;03m# 更改全局主程序和启动程序\u001b[39;00m\n\u001b[0;32m    877\u001b[0m     img \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mstatic\u001b[38;5;241m.\u001b[39mdata(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39myolo_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 图像\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     gt_box \u001b[38;5;241m=\u001b[39m \u001b[43mfluid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_box\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m[max_box_num, \u001b[38;5;241m4\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 边框\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     gt_label \u001b[38;5;241m=\u001b[39m fluid\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mdata(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_label\u001b[39m\u001b[38;5;124m'\u001b[39m, shape\u001b[38;5;241m=\u001b[39m[max_box_num], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 标签\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     feeder \u001b[38;5;241m=\u001b[39m fluid\u001b[38;5;241m.\u001b[39mDataFeeder(feed_list\u001b[38;5;241m=\u001b[39m[img, gt_box, gt_label],\n\u001b[0;32m    882\u001b[0m                               place\u001b[38;5;241m=\u001b[39mplace,\n\u001b[0;32m    883\u001b[0m                               program\u001b[38;5;241m=\u001b[39mmain_prog)  \u001b[38;5;66;03m# 定义feeder\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'paddle.fluid.layers' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "训练常基于dark-net的YOLOv3网络，目标检测\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "\n",
    "os.environ[\"FLAGS_fraction_of_gpu_memory_to_use\"] = '0.82'\n",
    "\n",
    "import uuid\n",
    "import numpy as np\n",
    "import time\n",
    "import six\n",
    "import math\n",
    "import random\n",
    "import paddle\n",
    "#import paddle.fluid as fluid\n",
    "import logging\n",
    "import xml.etree.ElementTree\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "#from paddle.fluid.initializer import MSRA\n",
    "#from paddle.fluid.param_attr import ParamAttr\n",
    "from paddle.regularizer import L2Decay\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "\n",
    "paddle.enable_static()\n",
    "\n",
    "logger = None  # 日志对象\n",
    "\n",
    "train_params = {\n",
    "    \"data_dir\": \"data/data6045\",  # 数据目录\n",
    "    \"train_list\": \"train.txt\",  # 训练集文件\n",
    "    \"eval_list\": \"eval.txt\",\n",
    "    \"class_dim\": -1,\n",
    "    \"label_dict\": {},  # 标签字典\n",
    "    \"num_dict\": {},\n",
    "    \"image_count\": -1,\n",
    "    \"continue_train\": True,  # 是否加载前一次的训练参数，接着训练\n",
    "    \"pretrained\": False,  # 是否预训练\n",
    "    \"pretrained_model_dir\": \"./pretrained-model\",\n",
    "    \"save_model_dir\": \"./yolo-model\",  # 模型保存目录\n",
    "    \"model_prefix\": \"yolo-v3\",  # 模型前缀\n",
    "    \"freeze_dir\": \"freeze_model\",\n",
    "    \"use_tiny\": True,  # 是否使用 裁剪 tiny 模型\n",
    "    \"max_box_num\": 20,  # 一幅图上最多有多少个目标\n",
    "    \"num_epochs\": 40,  # 训练轮次\n",
    "    \"train_batch_size\": 32,  # 对于完整yolov3，每一批的训练样本不能太多，内存会炸掉；如果使用tiny，可以适当大一些\n",
    "    \"use_gpu\": True,  # 是否使用GPU\n",
    "    \"yolo_cfg\": {  # YOLO模型参数\n",
    "        \"input_size\": [3, 448, 448],  # 原版的边长大小为608，为了提高训练速度和预测速度，此处压缩为448\n",
    "        \"anchors\": [7, 10, 12, 22, 24, 17, 22, 45, 46, 33, 43, 88, 85, 66, 115, 146, 275, 240],  # 锚点??\n",
    "        \"anchor_mask\": [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"yolo_tiny_cfg\": {  # YOLO tiny 模型参数\n",
    "        \"input_size\": [3, 256, 256],\n",
    "        \"anchors\": [6, 8, 13, 15, 22, 34, 48, 50, 81, 100, 205, 191],\n",
    "        \"anchor_mask\": [[3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"ignore_thresh\": 0.7,\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],\n",
    "    \"mode\": \"train\",\n",
    "    \"multi_data_reader_count\": 4,\n",
    "    \"apply_distort\": True,  # 是否做图像扭曲增强\n",
    "    \"nms_top_k\": 300,\n",
    "    \"nms_pos_k\": 300,\n",
    "    \"valid_thresh\": 0.01,\n",
    "    \"nms_thresh\": 0.45,  # 非最大值抑制阈值\n",
    "    \"image_distort_strategy\": {  # 图像扭曲策略\n",
    "        \"expand_prob\": 0.5,  # 扩展比率\n",
    "        \"expand_max_ratio\": 4,\n",
    "        \"hue_prob\": 0.5,  # 色调\n",
    "        \"hue_delta\": 18,\n",
    "        \"contrast_prob\": 0.5,  # 对比度\n",
    "        \"contrast_delta\": 0.5,\n",
    "        \"saturation_prob\": 0.5,  # 饱和度\n",
    "        \"saturation_delta\": 0.5,\n",
    "        \"brightness_prob\": 0.5,  # 亮度\n",
    "        \"brightness_delta\": 0.125\n",
    "    },\n",
    "    \"sgd_strategy\": {  # 梯度下降配置\n",
    "        \"learning_rate\": 0.002,\n",
    "        \"lr_epochs\": [30, 50, 65],  # 学习率衰减分段（3个数字分为4段）\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1]  # 每段采用的学习率，对应lr_epochs参数4段\n",
    "    },\n",
    "    \"early_stop\": {\n",
    "        \"sample_frequency\": 50,\n",
    "        \"successive_limit\": 3,\n",
    "        \"min_loss\": 2.5,\n",
    "        \"min_curr_map\": 0.84\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def init_train_parameters():\n",
    "    \"\"\"\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file_list = os.path.join(train_params['data_dir'], train_params['train_list'])  # 训练集\n",
    "    label_list = os.path.join(train_params['data_dir'], \"label_list\")  # 标签文件\n",
    "    index = 0\n",
    "\n",
    "    # codecs是专门用作编码转换通用模块\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        for line in lines:\n",
    "            train_params['num_dict'][index] = line.strip()\n",
    "            train_params['label_dict'][line.strip()] = index\n",
    "            index += 1\n",
    "        train_params['class_dim'] = index\n",
    "\n",
    "    with codecs.open(file_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        train_params['image_count'] = len(lines)  # 图片数量\n",
    "\n",
    "\n",
    "# 日志相关配置\n",
    "def init_log_config():  # 初始化日志相关配置\n",
    "    global logger\n",
    "\n",
    "    logger = logging.getLogger()  # 创建日志对象\n",
    "    logger.setLevel(logging.INFO)  # 设置日志级别\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\n",
    "\n",
    "    if not os.path.exists(log_path):  # 创建日志路径\n",
    "        os.makedirs(log_path)\n",
    "\n",
    "    log_name = os.path.join(log_path, 'train.log')  # 训练日志文件\n",
    "    fh = logging.FileHandler(log_name, mode='w')  # 打开文件句柄\n",
    "    fh.setLevel(logging.DEBUG)  # 设置级别\n",
    "\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "\n",
    "init_log_config()\n",
    "\n",
    "\n",
    "# 定义YOLO3网络结构：darknet-53\n",
    "class YOLOv3(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []  # 网络最终模型\n",
    "        self.downsample_ratio = 1  # 下采样率\n",
    "        self.anchor_mask = anchor_mask  # 计算卷积核？？？\n",
    "        self.anchors = anchors  # 锚点\n",
    "        self.class_num = class_num  # 类别数量\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3'\n",
    "\n",
    "    # 获取anchors\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    # 获取anchor_mask\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    # 卷积正则化函数: 卷积、批量正则化处理、leakrelu\n",
    "    def conv_bn(self,\n",
    "                input,  # 输入\n",
    "                num_filters,  # 卷积核数量\n",
    "                filter_size,  # 卷积核大小\n",
    "                stride,  # 步幅\n",
    "                padding,  # 填充\n",
    "                use_cudnn=True):\n",
    "        # 2d卷积操作\n",
    "        conv = fluid.layers.conv2d(input=input,\n",
    "                                   num_filters=num_filters,\n",
    "                                   filter_size=filter_size,\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   act=None,\n",
    "                                   use_cudnn=use_cudnn,  # 是否使用cudnn，cudnn利用cuda进行了加速处理\n",
    "                                   param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "                                   bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        # 在batch_norm中使用leaky的话，只能使用默认的alpha=0.02；如果需要设值，必须提出去单独来\n",
    "        # 正则化的目的，是为了防止过拟合，较小的L2值能防止过拟合\n",
    "        param_attr = ParamAttr(initializer=fluid.initializer.Normal(0., 0.02),\n",
    "                               regularizer=L2Decay(0.))\n",
    "        bias_attr = ParamAttr(initializer=fluid.initializer.Constant(0.0),\n",
    "                              regularizer=L2Decay(0.))\n",
    "        out = fluid.layers.batch_norm(input=conv, act=None,\n",
    "                                      param_attr=param_attr,\n",
    "                                      bias_attr=bias_attr)\n",
    "        # leaky_relu: Leaky ReLU是给所有负值赋予一个非零斜率\n",
    "        out = fluid.layers.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "    # 通过卷积实现降采样\n",
    "    # 如：原始图片大小448*448，降采样后大小为 ((448+2)-3)/2 + 1 = 224\n",
    "    def down_sample(self, input, num_filters, filter_size=3, stride=2, padding=1):\n",
    "        self.downsample_ratio *= 2  # 降采样率\n",
    "        return self.conv_bn(input,\n",
    "                            num_filters=num_filters,\n",
    "                            filter_size=filter_size,\n",
    "                            stride=stride,\n",
    "                            padding=padding)\n",
    "\n",
    "    # 基本块：包含两个卷积/正则化层，一个残差块\n",
    "    def basic_block(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        conv2 = self.conv_bn(conv1, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        out = fluid.layers.elementwise_add(x=input, y=conv2, act=None)  # 计算H(x)=F(x)+x\n",
    "        return out\n",
    "\n",
    "    # 创建多个basic_block\n",
    "    def layer_warp(self, input, num_filters, count):\n",
    "        res_out = self.basic_block(input, num_filters)\n",
    "        for j in range(1, count):\n",
    "            res_out = self.basic_block(res_out, num_filters)\n",
    "        return res_out\n",
    "\n",
    "    # 上采样\n",
    "    def up_sample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)  # 获取input的形状\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale  # 计算输出数据形状\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        # 矩阵放大(最邻插值法)\n",
    "        out = fluid.layers.resize_nearest(input=input,\n",
    "                                          scale=scale,\n",
    "                                          actual_shape=out_shape)\n",
    "        return out\n",
    "\n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        assert num_filters % 2 == 0, \"num_filters {} cannot be divided by 2\".format(num_filters)\n",
    "\n",
    "        conv = input\n",
    "        for j in range(2):\n",
    "            conv = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "            conv = self.conv_bn(conv, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        route = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    # 搭建网络模型 darknet-53\n",
    "    def net(self, img):\n",
    "        stages = [1, 2, 8, 8, 4]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than down_sample times\"\n",
    "        # 第一个卷积层: 256*256\n",
    "        conv1 = self.conv_bn(img, num_filters=32, filter_size=3, stride=1, padding=1)\n",
    "        # 第二个卷积层：128*128\n",
    "        downsample_ = self.down_sample(conv1, conv1.shape[1] * 2)  # 第二个参数为卷积核数量\n",
    "        blocks = []\n",
    "\n",
    "        # 循环创建basic_block组\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            block = self.layer_warp(downsample_,  # 输入数据\n",
    "                                    32 * (2 ** i),  # 卷积核数量\n",
    "                                    stage_count)  # 基本块数量\n",
    "            blocks.append(block)\n",
    "            if i < len(stages) - 1:  # 如果不是最后一组，做降采样\n",
    "                downsample_ = self.down_sample(block, block.shape[1] * 2)\n",
    "        blocks = blocks[-1:-4:-1]  # 取倒数三层，并且逆序，后面跨层级联需要\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)  # 连接route和block，按行\n",
    "\n",
    "            route, tip = self.yolo_detection_block(block,  # 输入\n",
    "                                                   num_filters=512 // (2 ** i))  # 卷积核数量\n",
    "\n",
    "            param_attr = ParamAttr(initializer=fluid.initializer.Normal(0., 0.02))\n",
    "            bias_attr = ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.))\n",
    "            block_out = fluid.layers.conv2d(input=tip,\n",
    "                                            # 5 elements represent x|y|h|w|score\n",
    "                                            num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),\n",
    "                                            filter_size=1,\n",
    "                                            stride=1,\n",
    "                                            padding=0,\n",
    "                                            act=None,\n",
    "                                            param_attr=param_attr,\n",
    "                                            bias_attr=bias_attr)\n",
    "            self.outputs.append(block_out)\n",
    "\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 256 // (2 ** i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.up_sample(route)  # 上采样\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "# Tiny(精简版)YOLO模型\n",
    "class YOLOv3Tiny(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []\n",
    "        self.downsample_ratio = 1\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.anchors = anchors\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3-tiny'\n",
    "\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                num_filters,\n",
    "                filter_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                num_groups=1,\n",
    "                use_cudnn=True):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            act=None,\n",
    "            groups=num_groups,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "            bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        out = fluid.layers.batch_norm(\n",
    "            input=conv, act='relu',\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02), regularizer=L2Decay(0.)),\n",
    "            bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def depthwise_conv_bn(self, input, filter_size=3, stride=1, padding=1):\n",
    "        num_filters = input.shape[1]\n",
    "        return self.conv_bn(input,\n",
    "                            num_filters=num_filters,\n",
    "                            filter_size=filter_size,\n",
    "                            stride=stride,\n",
    "                            padding=padding,\n",
    "                            num_groups=num_filters)\n",
    "\n",
    "    def down_sample(self, input, pool_size=2, pool_stride=2):\n",
    "        self.downsample_ratio *= 2\n",
    "        return fluid.layers.pool2d(input=input, pool_type='max', pool_size=pool_size,\n",
    "                                   pool_stride=pool_stride)\n",
    "\n",
    "    def basic_block(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=3, stride=1, padding=1)\n",
    "        out = self.down_sample(conv1)\n",
    "        return out\n",
    "\n",
    "    def up_sample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        out = fluid.layers.resize_nearest(\n",
    "            input=input,\n",
    "            scale=scale,\n",
    "            actual_shape=out_shape)\n",
    "        return out\n",
    "\n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        route = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    def net(self, img):\n",
    "        # darknet-tiny\n",
    "        stages = [16, 32, 64, 128, 256, 512]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than down_sample times\"\n",
    "        # 256x256\n",
    "        tmp = img\n",
    "        blocks = []\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            if i == len(stages) - 1:\n",
    "                block = self.conv_bn(tmp, stage_count, filter_size=3, stride=1, padding=1)\n",
    "                blocks.append(block)\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.conv_bn(blocks[-1], stage_count * 2, filter_size=1, stride=1, padding=0)\n",
    "                blocks.append(block)\n",
    "            else:\n",
    "                tmp = self.basic_block(tmp, stage_count)\n",
    "                blocks.append(tmp)\n",
    "\n",
    "        blocks = [blocks[-1], blocks[3]]\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo 中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)\n",
    "            if i < 1:\n",
    "                route, tip = self.yolo_detection_block(block, num_filters=256 // (2 ** i))\n",
    "            else:\n",
    "                tip = self.conv_bn(block, num_filters=256, filter_size=3, stride=1, padding=1)\n",
    "\n",
    "            param_attr = ParamAttr(initializer=fluid.initializer.Normal(0., 0.02))\n",
    "            bias_attr = ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.))\n",
    "            block_out = fluid.layers.conv2d(input=tip,\n",
    "                                            # 5 elements represent x|y|h|w|score\n",
    "                                            num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),\n",
    "                                            filter_size=1,\n",
    "                                            stride=1,\n",
    "                                            padding=0,\n",
    "                                            act=None,\n",
    "                                            param_attr=param_attr,\n",
    "                                            bias_attr=bias_attr)\n",
    "            self.outputs.append(block_out)\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 128 // (2 ** i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.up_sample(route)\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "def get_yolo(is_tiny, class_num, anchors, anchor_mask):\n",
    "    if is_tiny:\n",
    "        return YOLOv3Tiny(class_num, anchors, anchor_mask)\n",
    "    else:\n",
    "        return YOLOv3(class_num, anchors, anchor_mask)\n",
    "\n",
    "\n",
    "class Sampler(object):\n",
    "    \"\"\"\n",
    "    采样器，用于扣取采样\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_sample, max_trial, min_scale, max_scale,\n",
    "                 min_aspect_ratio, max_aspect_ratio, min_jaccard_overlap,\n",
    "                 max_jaccard_overlap):\n",
    "        self.max_sample = max_sample\n",
    "        self.max_trial = max_trial\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_aspect_ratio = min_aspect_ratio\n",
    "        self.max_aspect_ratio = max_aspect_ratio\n",
    "        self.min_jaccard_overlap = min_jaccard_overlap\n",
    "        self.max_jaccard_overlap = max_jaccard_overlap\n",
    "\n",
    "\n",
    "class bbox(object):\n",
    "    \"\"\"\n",
    "    外界矩形框\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "\n",
    "# 坐标转换，由[x1, y1, w, h]转换为[center_x, center_y, w, h]\n",
    "# 并转换为范围在[0, 1]之间的相对坐标\n",
    "def box_to_center_relative(box, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Convert COCO annotations box with format [x1, y1, w, h] to\n",
    "    center mode [center_x, center_y, w, h] and divide image width\n",
    "    and height to get relative value in range[0, 1]\n",
    "    \"\"\"\n",
    "    assert len(box) == 4, \"box should be a len(4) list or tuple\"\n",
    "    x, y, w, h = box\n",
    "\n",
    "    x1 = max(x, 0)\n",
    "    x2 = min(x + w - 1, img_width - 1)\n",
    "    y1 = max(y, 0)\n",
    "    y2 = min(y + h - 1, img_height - 1)\n",
    "\n",
    "    x = (x1 + x2) / 2 / img_width  # x中心坐标\n",
    "    y = (y1 + y2) / 2 / img_height  # y中心坐标\n",
    "    w = (x2 - x1) / img_width  # 框宽度/图片总宽度\n",
    "    h = (y2 - y1) / img_height  # 框高度/图片总高度\n",
    "\n",
    "    return np.array([x, y, w, h])\n",
    "\n",
    "\n",
    "# 调整图像大小\n",
    "def resize_img(img, sampled_labels, input_size):\n",
    "    target_size = input_size\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "# 计算交并比\n",
    "def box_iou_xywh(box1, box2):\n",
    "    assert box1.shape[-1] == 4, \"Box1 shape[-1] should be 4.\"\n",
    "    assert box2.shape[-1] == 4, \"Box2 shape[-1] should be 4.\"\n",
    "\n",
    "    # 取两个框的坐标\n",
    "    b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "    b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "    b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "    b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "    inter_x1 = np.maximum(b1_x1, b2_x1)\n",
    "    inter_x2 = np.minimum(b1_x2, b2_x2)\n",
    "    inter_y1 = np.maximum(b1_y1, b2_y1)\n",
    "    inter_y2 = np.minimum(b1_y2, b2_y2)\n",
    "    inter_w = inter_x2 - inter_x1 + 1  # 相交部分宽度\n",
    "    inter_h = inter_y2 - inter_y1 + 1  # 相交部分高度\n",
    "    inter_w[inter_w < 0] = 0\n",
    "    inter_h[inter_h < 0] = 0\n",
    "\n",
    "    inter_area = inter_w * inter_h  # 相交面积\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)  # 框1的面积\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)  # 框2的面积\n",
    "\n",
    "    return inter_area / (b1_area + b2_area - inter_area)  # 相集面积/并集面积\n",
    "\n",
    "\n",
    "# box裁剪\n",
    "def box_crop(boxes, labels, crop, img_shape):\n",
    "    x, y, w, h = map(float, crop)\n",
    "    im_w, im_h = map(float, img_shape)\n",
    "\n",
    "    boxes = boxes.copy()\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] - boxes[:, 2] / 2) * im_w, (boxes[:, 0] + boxes[:, 2] / 2) * im_w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] - boxes[:, 3] / 2) * im_h, (boxes[:, 1] + boxes[:, 3] / 2) * im_h\n",
    "\n",
    "    crop_box = np.array([x, y, x + w, y + h])\n",
    "    centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0\n",
    "    mask = np.logical_and(crop_box[:2] <= centers, centers <= crop_box[2:]).all(axis=1)\n",
    "\n",
    "    boxes[:, :2] = np.maximum(boxes[:, :2], crop_box[:2])\n",
    "    boxes[:, 2:] = np.minimum(boxes[:, 2:], crop_box[2:])\n",
    "    boxes[:, :2] -= crop_box[:2]\n",
    "    boxes[:, 2:] -= crop_box[:2]\n",
    "\n",
    "    mask = np.logical_and(mask, (boxes[:, :2] < boxes[:, 2:]).all(axis=1))\n",
    "    boxes = boxes * np.expand_dims(mask.astype('float32'), axis=1)\n",
    "    labels = labels * mask.astype('float32')\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] + boxes[:, 2]) / 2 / w, (boxes[:, 2] - boxes[:, 0]) / w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] + boxes[:, 3]) / 2 / h, (boxes[:, 3] - boxes[:, 1]) / h\n",
    "\n",
    "    return boxes, labels, mask.sum()\n",
    "\n",
    "\n",
    "# 图像增加：对比度，饱和度，明暗，颜色，扩张\n",
    "def random_brightness(img):  # 亮度\n",
    "    prob = np.random.uniform(0, 1)\n",
    "\n",
    "    if prob < train_params['image_distort_strategy']['brightness_prob']:\n",
    "        brightness_delta = train_params['image_distort_strategy']['brightness_delta']  # 默认值0.125\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1  # 产生均匀分布随机值\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)  # 调整图像亮度\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img):  # 对比度\n",
    "    prob = np.random.uniform(0, 1)\n",
    "\n",
    "    if prob < train_params['image_distort_strategy']['contrast_prob']:\n",
    "        contrast_delta = train_params['image_distort_strategy']['contrast_delta']\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img):  # 饱和度\n",
    "    prob = np.random.uniform(0, 1)\n",
    "\n",
    "    if prob < train_params['image_distort_strategy']['saturation_prob']:\n",
    "        saturation_delta = train_params['image_distort_strategy']['saturation_delta']\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img):  # 色调\n",
    "    prob = np.random.uniform(0, 1)\n",
    "\n",
    "    if prob < train_params['image_distort_strategy']['hue_prob']:\n",
    "        hue_delta = train_params['image_distort_strategy']['hue_delta']\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_image(img):  # 图像扭曲\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob > 0.5:\n",
    "        img = random_brightness(img)\n",
    "        img = random_contrast(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "    else:\n",
    "        img = random_brightness(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "        img = random_contrast(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "# 随机裁剪\n",
    "def random_crop(img, boxes, labels, scales=[0.3, 1.0], max_ratio=2.0, constraints=None, max_trial=50):\n",
    "    if random.random() > 0.6:\n",
    "        return img, boxes, labels\n",
    "    if len(boxes) == 0:\n",
    "        return img, boxes, labels\n",
    "\n",
    "    if not constraints:\n",
    "        constraints = [(0.1, 1.0),\n",
    "                       (0.3, 1.0),\n",
    "                       (0.5, 1.0),\n",
    "                       (0.7, 1.0),\n",
    "                       (0.9, 1.0),\n",
    "                       (0.0, 1.0)]  # 最小/最大交并比值\n",
    "\n",
    "    w, h = img.size\n",
    "    crops = [(0, 0, w, h)]\n",
    "\n",
    "    for min_iou, max_iou in constraints:\n",
    "        for _ in range(max_trial):\n",
    "            scale = random.uniform(scales[0], scales[1])\n",
    "            aspect_ratio = random.uniform(max(1 / max_ratio, scale * scale), \\\n",
    "                                          min(max_ratio, 1 / scale / scale))\n",
    "            crop_h = int(h * scale / np.sqrt(aspect_ratio))\n",
    "            crop_w = int(w * scale * np.sqrt(aspect_ratio))\n",
    "            crop_x = random.randrange(w - crop_w)\n",
    "            crop_y = random.randrange(h - crop_h)\n",
    "            crop_box = np.array([[\n",
    "                (crop_x + crop_w / 2.0) / w,\n",
    "                (crop_y + crop_h / 2.0) / h,\n",
    "                crop_w / float(w),\n",
    "                crop_h / float(h)\n",
    "            ]])\n",
    "\n",
    "            iou = box_iou_xywh(crop_box, boxes)\n",
    "            if min_iou <= iou.min() and max_iou >= iou.max():\n",
    "                crops.append((crop_x, crop_y, crop_w, crop_h))\n",
    "                break\n",
    "\n",
    "    while crops:\n",
    "        crop = crops.pop(np.random.randint(0, len(crops)))\n",
    "        crop_boxes, crop_labels, box_num = box_crop(boxes, labels, crop, (w, h))\n",
    "        if box_num < 1:\n",
    "            continue\n",
    "        img = img.crop((crop[0], crop[1], crop[0] + crop[2],\n",
    "                        crop[1] + crop[3])).resize(img.size, Image.LANCZOS)\n",
    "        return img, crop_boxes, crop_labels\n",
    "    return img, boxes, labels\n",
    "\n",
    "\n",
    "# 扩张\n",
    "def random_expand(img, gtboxes, keep_ratio=True):\n",
    "    if np.random.uniform(0, 1) < train_params['image_distort_strategy']['expand_prob']:\n",
    "        return img, gtboxes\n",
    "\n",
    "    max_ratio = train_params['image_distort_strategy']['expand_max_ratio']\n",
    "    w, h = img.size\n",
    "    c = 3\n",
    "    ratio_x = random.uniform(1, max_ratio)\n",
    "    if keep_ratio:\n",
    "        ratio_y = ratio_x\n",
    "    else:\n",
    "        ratio_y = random.uniform(1, max_ratio)\n",
    "    oh = int(h * ratio_y)\n",
    "    ow = int(w * ratio_x)\n",
    "    off_x = random.randint(0, ow - w)\n",
    "    off_y = random.randint(0, oh - h)\n",
    "\n",
    "    out_img = np.zeros((oh, ow, c), np.uint8)\n",
    "    for i in range(c):\n",
    "        out_img[:, :, i] = train_params['mean_rgb'][i]\n",
    "\n",
    "    out_img[off_y: off_y + h, off_x: off_x + w, :] = img\n",
    "    gtboxes[:, 0] = ((gtboxes[:, 0] * w) + off_x) / float(ow)\n",
    "    gtboxes[:, 1] = ((gtboxes[:, 1] * h) + off_y) / float(oh)\n",
    "    gtboxes[:, 2] = gtboxes[:, 2] / ratio_x\n",
    "    gtboxes[:, 3] = gtboxes[:, 3] / ratio_y\n",
    "\n",
    "    return Image.fromarray(out_img), gtboxes\n",
    "\n",
    "\n",
    "# 预处理：图像样本增强，维度转换\n",
    "def preprocess(img, bbox_labels, input_size, mode):\n",
    "    img_width, img_height = img.size\n",
    "    sample_labels = np.array(bbox_labels)\n",
    "\n",
    "    if mode == 'train':\n",
    "        if train_params['apply_distort']:  # 是否扭曲增强\n",
    "            img = distort_image(img)\n",
    "\n",
    "        img, gtboxes = random_expand(img, sample_labels[:, 1:5])  # 扩展增强\n",
    "        img, gtboxes, gtlabels = random_crop(img, gtboxes, sample_labels[:, 0])  # 随机裁剪\n",
    "        sample_labels[:, 0] = gtlabels\n",
    "        sample_labels[:, 1:5] = gtboxes\n",
    "\n",
    "    img = resize_img(img, sample_labels, input_size)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img -= train_params['mean_rgb']\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "    img *= 0.007843\n",
    "    return img, sample_labels\n",
    "\n",
    "\n",
    "# 数据读取器\n",
    "# 根据样本文件，读取图片、并做数据增强，返回图片数据、边框、标签\n",
    "def custom_reader(file_list, data_dir, input_size, mode):\n",
    "    def reader():\n",
    "        np.random.shuffle(file_list)  # 打乱文件列表\n",
    "\n",
    "        for line in file_list:  # 读取行，每行一个图片及标注\n",
    "            if mode == 'train' or mode == 'eval':\n",
    "                ######################  以下可能是需要自定义修改的部分   ############################\n",
    "                parts = line.split('\\t')  # 按照tab键拆分\n",
    "                image_path = parts[0]\n",
    "\n",
    "                img = Image.open(os.path.join(data_dir, image_path)) # 读取图像数据\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                im_width, im_height = img.size\n",
    "\n",
    "                # bbox 的列表，每一个元素为这样\n",
    "                # layout: label | x-center | y-cneter | width | height | difficult\n",
    "                bbox_labels = []\n",
    "                for object_str in parts[1:]:  # 循环处理每一个目标标注信息\n",
    "                    if len(object_str) <= 1:\n",
    "                        continue\n",
    "\n",
    "                    bbox_sample = []\n",
    "                    object = json.loads(object_str)\n",
    "                    bbox_sample.append(float(train_params['label_dict'][object['value']]))\n",
    "                    bbox = object['coordinate']  # 获取框坐标\n",
    "                    # 计算x,y,w,h\n",
    "                    box = [bbox[0][0], bbox[0][1], bbox[1][0] - bbox[0][0], bbox[1][1] - bbox[0][1]]\n",
    "                    bbox = box_to_center_relative(box, im_height, im_width)  # 坐标转换\n",
    "                    bbox_sample.append(float(bbox[0]))\n",
    "                    bbox_sample.append(float(bbox[1]))\n",
    "                    bbox_sample.append(float(bbox[2]))\n",
    "                    bbox_sample.append(float(bbox[3]))\n",
    "                    difficult = float(0)\n",
    "                    bbox_sample.append(difficult)\n",
    "                    bbox_labels.append(bbox_sample)\n",
    "                ######################  可能需要自定义修改部分结束   ############################\n",
    "\n",
    "                if len(bbox_labels) == 0:\n",
    "                    continue\n",
    "\n",
    "                img, sample_labels = preprocess(img, bbox_labels, input_size, mode)  # 预处理\n",
    "                # sample_labels = np.array(sample_labels)\n",
    "                if len(sample_labels) == 0:\n",
    "                    continue\n",
    "\n",
    "                boxes = sample_labels[:, 1:5]  # 坐标\n",
    "                lbls = sample_labels[:, 0].astype('int32')  # 标签\n",
    "                difficults = sample_labels[:, -1].astype('int32')\n",
    "                max_box_num = train_params['max_box_num']  # 一副图像最多多少个目标物体\n",
    "                cope_size = max_box_num if len(boxes) >= max_box_num else len(boxes)  # 控制最大目标数量\n",
    "                ret_boxes = np.zeros((max_box_num, 4), dtype=np.float32)\n",
    "                ret_lbls = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_difficults = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_boxes[0: cope_size] = boxes[0: cope_size]\n",
    "                ret_lbls[0: cope_size] = lbls[0: cope_size]\n",
    "                ret_difficults[0: cope_size] = difficults[0: cope_size]\n",
    "\n",
    "                yield img, ret_boxes, ret_lbls\n",
    "\n",
    "            elif mode == 'test':\n",
    "                img_path = os.path.join(line)\n",
    "\n",
    "                yield Image.open(img_path)\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "# 批量、随机数据读取器\n",
    "def single_custom_reader(file_path, data_dir, input_size, mode):\n",
    "    file_path = os.path.join(data_dir, file_path)\n",
    "\n",
    "    images = [line.strip() for line in open(file_path)]\n",
    "    reader = custom_reader(images, data_dir, input_size, mode)\n",
    "    reader = paddle.reader.shuffle(reader, train_params['train_batch_size'])\n",
    "    reader = paddle.batch(reader, train_params['train_batch_size'])\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "# 定义优化器\n",
    "def optimizer_sgd_setting():\n",
    "    batch_size = train_params[\"train_batch_size\"]  # batch大小\n",
    "    iters = train_params[\"image_count\"] // batch_size  # 计算轮次\n",
    "    iters = 1 if iters < 1 else iters\n",
    "    learning_strategy = train_params['sgd_strategy']\n",
    "    lr = learning_strategy['learning_rate']  # 学习率\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "    logger.info(\"origin learning rate: {0} boundaries: {1}  values: {2}\".format(lr, boundaries, values))\n",
    "\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values),  # 分段衰减学习率\n",
    "        # learning_rate=lr,\n",
    "        regularization=fluid.regularizer.L2Decay(0.00005))\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "# 创建program, feeder及yolo模型\n",
    "def build_program_with_feeder(main_prog, startup_prog, place):\n",
    "    max_box_num = train_params['max_box_num']\n",
    "    ues_tiny = train_params['use_tiny']  # 获取是否使用tiny yolo参数\n",
    "    yolo_config = train_params['yolo_tiny_cfg'] if ues_tiny else train_params['yolo_cfg']\n",
    "\n",
    "    with fluid.program_guard(main_prog, startup_prog):  # 更改全局主程序和启动程序\n",
    "        img = paddle.static.data(name='img', shape=yolo_config['input_size'], dtype='float32')  # 图像\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[max_box_num, 4], dtype='float32')  # 边框\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[max_box_num], dtype='int32')  # 标签\n",
    "\n",
    "        feeder = fluid.DataFeeder(feed_list=[img, gt_box, gt_label],\n",
    "                                  place=place,\n",
    "                                  program=main_prog)  # 定义feeder\n",
    "        reader = single_custom_reader(train_params['train_list'],\n",
    "                                      train_params['data_dir'],\n",
    "                                      yolo_config['input_size'], 'train')  # 读取器\n",
    "        # 获取yolo参数\n",
    "        ues_tiny = train_params['use_tiny']\n",
    "        yolo_config = train_params['yolo_tiny_cfg'] if ues_tiny else train_params['yolo_cfg']\n",
    "\n",
    "        with fluid.unique_name.guard():\n",
    "            # 创建yolo模型\n",
    "            model = get_yolo(ues_tiny, train_params['class_dim'], yolo_config['anchors'],\n",
    "                             yolo_config['anchor_mask'])\n",
    "            outputs = model.net(img)\n",
    "        return feeder, reader, get_loss(model, outputs, gt_box, gt_label)\n",
    "\n",
    "\n",
    "# 损失函数\n",
    "def get_loss(model, outputs, gt_box, gt_label):\n",
    "    losses = []\n",
    "    downsample_ratio = model.get_downsample_ratio()\n",
    "\n",
    "    with fluid.unique_name.guard('train'):\n",
    "        for i, out in enumerate(outputs):\n",
    "            loss = fluid.layers.yolov3_loss(x=out,\n",
    "                                            gt_box=gt_box,  # 真实边框\n",
    "                                            gt_label=gt_label,  # 标签\n",
    "                                            anchors=model.get_anchors(),  # 锚点\n",
    "                                            anchor_mask=model.get_anchor_mask()[i],\n",
    "                                            class_num=model.get_class_num(),\n",
    "                                            ignore_thresh=train_params['ignore_thresh'],\n",
    "                                            # 对于类别不多的情况，设置为 False 会更合适一些，不然 score 会很小\n",
    "                                            use_label_smooth=False,\n",
    "                                            downsample_ratio=downsample_ratio)\n",
    "            losses.append(fluid.layers.reduce_mean(loss))\n",
    "            downsample_ratio //= 2\n",
    "        loss = sum(losses)\n",
    "        optimizer = optimizer_sgd_setting()\n",
    "        optimizer.minimize(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "# 持久化参数加载\n",
    "def load_pretrained_params(exe, program):\n",
    "    if train_params['continue_train'] and os.path.exists(train_params['save_model_dir']):\n",
    "        logger.info('load param from retrain model')\n",
    "        fluid.io.load_persistables(executor=exe,\n",
    "                                   dirname=train_params['save_model_dir'],\n",
    "                                   main_program=program)\n",
    "    elif train_params['pretrained'] and os.path.exists(train_params['pretrained_model_dir']):\n",
    "        logger.info('load param from pretrained model')\n",
    "\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(train_params['pretrained_model_dir'], var.name))\n",
    "\n",
    "        fluid.io.load_vars(exe, train_params['pretrained_model_dir'], main_program=program,\n",
    "                           predicate=if_exist)\n",
    "\n",
    "\n",
    "# 执行训练\n",
    "def train():\n",
    "    init_log_config()\n",
    "    init_train_parameters()\n",
    "\n",
    "    logger.info(\"start train YOLOv3, train params:%s\", str(train_params))\n",
    "    logger.info(\"create place, use gpu:\" + str(train_params['use_gpu']))\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if train_params['use_gpu'] else fluid.CPUPlace()\n",
    "\n",
    "    logger.info(\"build network and program\")\n",
    "    train_program = fluid.Program()\n",
    "    start_program = fluid.Program()\n",
    "    feeder, reader, loss = build_program_with_feeder(train_program, start_program, place)\n",
    "\n",
    "    logger.info(\"build executor and init params\")\n",
    "\n",
    "    exe = fluid.Executor(place)\n",
    "    exe.run(start_program)\n",
    "    train_fetch_list = [loss.name]\n",
    "    load_pretrained_params(exe, train_program)  # 加载模型及参数\n",
    "\n",
    "    stop_strategy = train_params['early_stop']\n",
    "    successive_limit = stop_strategy['successive_limit']\n",
    "    sample_freq = stop_strategy['sample_frequency']\n",
    "    min_curr_map = stop_strategy['min_curr_map']\n",
    "    min_loss = stop_strategy['min_loss']\n",
    "    stop_train = False\n",
    "    successive_count = 0\n",
    "    total_batch_count = 0\n",
    "    valid_thresh = train_params['valid_thresh']\n",
    "    nms_thresh = train_params['nms_thresh']\n",
    "    current_best_loss = 10000000000.0\n",
    "\n",
    "    # 开始迭代训练\n",
    "    for pass_id in range(train_params[\"num_epochs\"]):\n",
    "        logger.info(\"current pass: {}, start read image\".format(pass_id))\n",
    "        batch_id = 0\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_id, data in enumerate(reader()):\n",
    "            t1 = time.time()\n",
    "\n",
    "            loss = exe.run(train_program,\n",
    "                           feed=feeder.feed(data),\n",
    "                           fetch_list=train_fetch_list)  # 执行训练\n",
    "\n",
    "            period = time.time() - t1\n",
    "            loss = np.mean(np.array(loss))\n",
    "            total_loss += loss\n",
    "            batch_id += 1\n",
    "            total_batch_count += 1\n",
    "\n",
    "            if batch_id % 10 == 0:  # 调整日志输出的频率\n",
    "                logger.info(\n",
    "                    \"pass {}, trainbatch {}, loss {} time {}\".format(pass_id, batch_id, loss, \"%2.2f sec\" % period))\n",
    "\n",
    "        pass_mean_loss = total_loss / batch_id\n",
    "        logger.info(\"pass {0} train result, current pass mean loss: {1}\".format(pass_id, pass_mean_loss))\n",
    "\n",
    "        # 采用每训练完一轮停止办法，可以调整为更精细的保存策略\n",
    "        if pass_mean_loss < current_best_loss:\n",
    "            logger.info(\"temp save {} epcho train result, current best pass loss {}\".format(pass_id, pass_mean_loss))\n",
    "            fluid.io.save_persistables(dirname=train_params['save_model_dir'], main_program=train_program,\n",
    "                                       executor=exe)\n",
    "            current_best_loss = pass_mean_loss\n",
    "\n",
    "    logger.info(\"training till last epcho, end training\")\n",
    "    fluid.io.save_persistables(dirname=train_params['save_model_dir'], main_program=train_program, executor=exe)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固化保存模型\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import codecs\n",
    "\n",
    "\n",
    "init_train_parameters()\n",
    "\n",
    "\n",
    "def freeze_model():\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "\n",
    "    ues_tiny = train_params['use_tiny']\n",
    "    yolo_config = train_params['yolo_tiny_cfg'] if ues_tiny else train_params['yolo_cfg']\n",
    "    path = train_params['save_model_dir']\n",
    "\n",
    "    model = get_yolo(ues_tiny, train_params['class_dim'],\n",
    "                     yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "    image = fluid.layers.data(name='image', shape=yolo_config['input_size'], dtype='float32')\n",
    "    image_shape = fluid.layers.data(name=\"image_shape\", shape=[2], dtype='int32')\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    outputs = model.net(image)\n",
    "    downsample_ratio = model.get_downsample_ratio()\n",
    "\n",
    "    for i, out in enumerate(outputs):\n",
    "        box, score = fluid.layers.yolo_box(x=out,\n",
    "                                           img_size=image_shape,\n",
    "                                           anchors=model.get_yolo_anchors()[i],\n",
    "                                           class_num=model.get_class_num(),\n",
    "                                           conf_thresh=train_params['valid_thresh'],\n",
    "                                           downsample_ratio=downsample_ratio,\n",
    "                                           name=\"yolo_box_\" + str(i))\n",
    "        boxes.append(box)\n",
    "        scores.append(fluid.layers.transpose(score, perm=[0, 2, 1]))\n",
    "        downsample_ratio //= 2\n",
    "\n",
    "    pred = fluid.layers.multiclass_nms(bboxes=fluid.layers.concat(boxes, axis=1),\n",
    "                                       scores=fluid.layers.concat(scores, axis=2),\n",
    "                                       score_threshold=train_params['valid_thresh'],\n",
    "                                       nms_top_k=train_params['nms_top_k'],\n",
    "                                       keep_top_k=train_params['nms_pos_k'],\n",
    "                                       nms_threshold=train_params['nms_thresh'],\n",
    "                                       background_label=-1,\n",
    "                                       name=\"multiclass_nms\")\n",
    "\n",
    "    freeze_program = fluid.default_main_program()\n",
    "\n",
    "    fluid.io.load_persistables(exe, path, freeze_program)\n",
    "    freeze_program = freeze_program.clone(for_test=True)\n",
    "    print(\"freeze out: {0}, pred layout: {1}\".format(train_params['freeze_dir'], pred))\n",
    "    # 保存模型\n",
    "    fluid.io.save_inference_model(train_params['freeze_dir'],\n",
    "                                  ['image', 'image_shape'],\n",
    "                                  pred, exe, freeze_program)\n",
    "    print(\"freeze end\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "import codecs\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import math\n",
    "import functools\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "from collections import namedtuple\n",
    "\n",
    "init_train_parameters()\n",
    "ues_tiny = train_params['use_tiny']\n",
    "yolo_config = train_params['yolo_tiny_cfg'] if ues_tiny else train_params['yolo_cfg']\n",
    "\n",
    "target_size = yolo_config['input_size']\n",
    "anchors = yolo_config['anchors']\n",
    "anchor_mask = yolo_config['anchor_mask']\n",
    "label_dict = train_params['num_dict']\n",
    "class_dim = train_params['class_dim']\n",
    "print(\"label_dict:{} class dim:{}\".format(label_dict, class_dim))\n",
    "\n",
    "place = fluid.CUDAPlace(0) if train_params['use_gpu'] else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "path = train_params['freeze_dir']\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=path, executor=exe)\n",
    "\n",
    "\n",
    "# 给图片画上外接矩形框\n",
    "def draw_bbox_image(img, boxes, labels, save_name):\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    draw = ImageDraw.Draw(img) # 图像绘制对象\n",
    "    for box, label in zip(boxes, labels):\n",
    "        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]\n",
    "        draw.rectangle((xmin, ymin, xmax, ymax), None, 'red') # 绘制矩形\n",
    "        draw.text((xmin, ymin), label_dict[int(label)], (255, 255, 0)) # 绘制标签\n",
    "    img.save(save_name)\n",
    "    display(img)\n",
    "\n",
    "\n",
    "def resize_img(img, target_size):\n",
    "    \"\"\"\n",
    "    保持比例的缩放图片\n",
    "    :param img:\n",
    "    :param target_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = img.resize(target_size[1:], Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_image(img_path):\n",
    "    \"\"\"\n",
    "    读取图片\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin = Image.open(img_path)\n",
    "    img = resize_img(origin, target_size)\n",
    "    resized_img = img.copy()\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = np.array(img).astype('float32').transpose((2, 0, 1))  # HWC to CHW\n",
    "    img -= 127.5\n",
    "    img *= 0.007843\n",
    "    img = img[np.newaxis, :]\n",
    "    return origin, img, resized_img\n",
    "\n",
    "\n",
    "def infer(image_path):\n",
    "    \"\"\"\n",
    "    预测，将结果保存到一副新的图片中\n",
    "    :param image_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin, tensor_img, resized_img = read_image(image_path)\n",
    "    input_w, input_h = origin.size[0], origin.size[1]\n",
    "    image_shape = np.array([input_h, input_w], dtype='int32')\n",
    "    # print(\"image shape high:{0}, width:{1}\".format(input_h, input_w))\n",
    "\n",
    "    t1 = time.time()\n",
    "    # 执行预测\n",
    "    batch_outputs = exe.run(inference_program,\n",
    "                            feed={feed_target_names[0]: tensor_img,\n",
    "                                  feed_target_names[1]: image_shape[np.newaxis, :]},\n",
    "                            fetch_list=fetch_targets,\n",
    "                            return_numpy=False)\n",
    "    period = time.time() - t1\n",
    "    print(\"predict cost time:{0}\".format(\"%2.2f sec\" % period))\n",
    "    bboxes = np.array(batch_outputs[0])  # 预测结果\n",
    "    # print(bboxes)\n",
    "\n",
    "    if bboxes.shape[1] != 6:\n",
    "        print(\"No object found in {}\".format(image_path))\n",
    "        return\n",
    "    labels = bboxes[:, 0].astype('int32') # 类别\n",
    "    scores = bboxes[:, 1].astype('float32') # 概率\n",
    "    boxes = bboxes[:, 2:].astype('float32') # 边框\n",
    "\n",
    "    last_dot_index = image_path.rfind('.')\n",
    "    out_path = image_path[:last_dot_index]\n",
    "    out_path += '-result.jpg'\n",
    "    draw_bbox_image(origin, boxes, labels, out_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_name = sys.argv[1]\n",
    "    image_path = image_name\n",
    "    image_path = \"data/data6045/lslm-test/2.jpg\"\n",
    "    infer(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
